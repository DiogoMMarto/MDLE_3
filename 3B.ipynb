{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cbf15282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyspark\n",
    "from pyspark.sql import SparkSession , DataFrame\n",
    "from pyspark.ml.feature import BucketedRandomProjectionLSH\n",
    "from pyspark.ml.linalg import SparseVector , VectorUDT , Vectors\n",
    "from pyspark.sql.functions import col, collect_list, struct , udf , avg , max , sum as spark_sum\n",
    "from pyspark.sql.types import FloatType , ArrayType, StructType, StructField , IntegerType\n",
    "import collections\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2935eba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Eclipse Adoptium\\jdk-11.0.27.6-hotspot\\\n"
     ]
    }
   ],
   "source": [
    "# I need this to run comment this code if you don't need it\n",
    "os.environ['PYSPARK_PYTHON'] = '.venv/Scripts/python.exe'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = '.venv/Scripts/python.exe'\n",
    "print(os.environ.get(\"JAVA_HOME\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7966a21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark: SparkSession = SparkSession.builder \\\n",
    "    .appName(\"CF movielens\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4cd97957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ratings: 100836\n",
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|     1|      1|   4.0|\n",
      "|     1|      3|   4.0|\n",
      "|     1|      6|   4.0|\n",
      "|     1|     47|   5.0|\n",
      "|     1|     50|   5.0|\n",
      "+------+-------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = \"ml-latest-small/ml-latest-small/ratings.csv\"\n",
    "ratings_df = spark.read.csv(file_path, header=True, inferSchema=True) \\\n",
    "    .drop(\"timestamp\")\n",
    "print(\"Number of ratings:\", ratings_df.count())\n",
    "ratings_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57ea1840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training ratings: 90673\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = ratings_df.randomSplit([0.9, 0.1], seed=42)\n",
    "print(\"Number of training ratings:\", train_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1b12f65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average rating in training set: 3.503325135376573\n",
      "+------+---------------------+\n",
      "|userId|rating_deviation_user|\n",
      "+------+---------------------+\n",
      "|   148|  0.23417486462342696|\n",
      "|   463|   0.3932265887613582|\n",
      "|   471|   0.4057657737143363|\n",
      "|   496| -0.15147328352472123|\n",
      "|   243|    0.610960578909141|\n",
      "+------+---------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------+----------------------+\n",
      "|movieId|rating_deviation_movie|\n",
      "+-------+----------------------+\n",
      "|   1580|  -0.02144107740555823|\n",
      "|   2366|   0.13667486462342726|\n",
      "|   3175|   0.08363138636255751|\n",
      "|  32460|    0.7466748646234271|\n",
      "|   1238|    0.5522304201789825|\n",
      "+-------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+------+-------+---------------+------+\n",
      "|userId|movieId|baseline_rating|rating|\n",
      "+------+-------+---------------+------+\n",
      "|     1|      1|      4.7871666|   4.0|\n",
      "|     1|      3|      4.1031566|   4.0|\n",
      "|     1|      6|       4.805284|   4.0|\n",
      "|     1|     47|      4.8449597|   5.0|\n",
      "|     1|     50|      5.1087117|   5.0|\n",
      "+------+-------+---------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_rating = train_df.agg({\"rating\": \"avg\"}).collect()[0][0]\n",
    "print(\"Average rating in training set:\", avg_rating)\n",
    "# (avg rating of user x ) - μ\n",
    "rating_deviation_of_user = train_df.groupBy(\"userId\") \\\n",
    "    .agg(avg(\"rating\").alias(\"avg_rating\")) \\\n",
    "    .withColumn(\"rating_deviation_user\", col(\"avg_rating\") - avg_rating) \\\n",
    "    .select(\"userId\", \"rating_deviation_user\")\n",
    "    \n",
    "rating_deviation_of_user_dict = rating_deviation_of_user.rdd \\\n",
    "    .map(lambda row: (row.userId, row.rating_deviation_user)) \\\n",
    "    .collectAsMap()\n",
    "rating_deviation_of_user.show(5)\n",
    "\n",
    "# (avg rating of user x - ration deviation ) - μ\n",
    "rating_deviation_of_movie = train_df \\\n",
    "    .groupBy(\"movieId\") \\\n",
    "    .agg(avg(\"rating\").alias(\"avg_rating\")) \\\n",
    "    .withColumn(\"rating_deviation_movie\", col(\"avg_rating\") - avg_rating) \\\n",
    "    .select(\"movieId\", \"rating_deviation_movie\")\n",
    "rating_deviation_of_movie.show(5)\n",
    "rating_deviation_of_movie_dict = rating_deviation_of_movie.rdd \\\n",
    "    .map(lambda row: (row.movieId, row.rating_deviation_movie)) \\\n",
    "    .collectAsMap()\n",
    "\n",
    "def calculate_baseline_rating(userId, movieId):\n",
    "    user_deviation = rating_deviation_of_user_dict.get(userId, 0.0)\n",
    "    movie_deviation = rating_deviation_of_movie_dict.get(movieId, 0.0)\n",
    "    return avg_rating + user_deviation + movie_deviation\n",
    "\n",
    "calculate_baseline_rating_udf = udf(calculate_baseline_rating, FloatType())\n",
    "\n",
    "train_df = train_df.withColumn(\n",
    "    \"baseline_rating\",\n",
    "    calculate_baseline_rating_udf(col(\"userId\"), col(\"movieId\"))\n",
    ")\n",
    "train_df.select(\"userId\", \"movieId\", \"baseline_rating\" ,\"rating\").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a5fba961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|     1|    101|   5.0|\n",
      "|     1|    151|   5.0|\n",
      "|     1|    943|   4.0|\n",
      "|     1|   1031|   5.0|\n",
      "|     1|   1220|   5.0|\n",
      "+------+-------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af392025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of baseline model: 0.9062214757366772\n"
     ]
    }
   ],
   "source": [
    "# calculate RMSE\n",
    "def calculate_rmse(predictions):\n",
    "    predictions = predictions.withColumnRenamed(\"rating\", \"actual_rating\")\n",
    "    predictions = predictions.withColumnRenamed(\"predicted_rating\", \"predicted_rating\")\n",
    "    rmse = predictions.withColumn(\n",
    "        \"squared_error\",\n",
    "        (col(\"actual_rating\") - col(\"predicted_rating\")) ** 2\n",
    "    ).agg({\"squared_error\": \"avg\"}).collect()[0][0] ** 0.5\n",
    "    return rmse\n",
    "\n",
    "predicted_ratings_df = test_df.withColumn(\n",
    "    \"predicted_rating\",\n",
    "    calculate_baseline_rating_udf(col(\"userId\"), col(\"movieId\"))\n",
    ")\n",
    "rmse = calculate_rmse(predicted_ratings_df)\n",
    "print(\"RMSE of baseline model:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "90b18281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-----------+\n",
      "|movieId|      ratings_vector|num_ratings|\n",
      "+-------+--------------------+-----------+\n",
      "|      1|(611,[1,5,7,17,18...|        197|\n",
      "|      2|(611,[6,8,18,19,2...|         94|\n",
      "|      3|(611,[1,6,19,32,4...|         46|\n",
      "|      4|(611,[6,14,84,262...|          6|\n",
      "|      5|(611,[6,31,43,45,...|         47|\n",
      "|      6|(611,[1,6,11,18,2...|         94|\n",
      "|      7|(611,[6,14,19,31,...|         50|\n",
      "|      8|(611,[6,20,43,274...|          8|\n",
      "|      9|(611,[151,179,217...|         15|\n",
      "|     10|(611,[6,8,11,19,2...|        119|\n",
      "|     11|(611,[6,8,33,35,3...|         55|\n",
      "|     12|(611,[19,44,120,1...|         18|\n",
      "|     13|(611,[6,19,20,288...|          6|\n",
      "|     14|(611,[90,109,182,...|         16|\n",
      "|     15|(611,[6,19,93,136...|         12|\n",
      "|     16|(611,[6,18,28,42,...|         72|\n",
      "|     17|(611,[6,31,33,38,...|         62|\n",
      "|     18|(611,[44,66,95,10...|         18|\n",
      "|     19|(611,[6,14,21,40,...|         79|\n",
      "|     20|(611,[78,199,217,...|         12|\n",
      "+-------+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3456"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_user = train_df.select(\"userId\").distinct().count() +1\n",
    "\n",
    "@udf(returnType=VectorUDT())\n",
    "def build_sparse_vector(ratings_list):\n",
    "    if not ratings_list:\n",
    "        return Vectors.sparse(length_user, [], [])\n",
    "        \n",
    "    user_rating_map = collections.OrderedDict(sorted([(r[0], r[1]) for r in ratings_list]))\n",
    "    user_ids = [int(k) for k in user_rating_map.keys()] # Ensure integer indices\n",
    "    values = list(user_rating_map.values())\n",
    "    return Vectors.sparse(length_user, user_ids, values)\n",
    "\n",
    "sparse_vector_df = train_df.groupBy(\"movieId\") \\\n",
    "    .agg(collect_list(struct(\"userId\", \"rating\")).alias(\"ratings\")) \\\n",
    "    .select(\"movieId\", build_sparse_vector(col(\"ratings\")).alias(\"ratings_vector\"))\n",
    "    \n",
    "@udf(returnType=IntegerType())\n",
    "def get_num_ratings(vector: SparseVector):\n",
    "    return len(vector.values)\n",
    "sparse_vector_df = sparse_vector_df.withColumn(\n",
    "    \"num_ratings\",\n",
    "    get_num_ratings(col(\"ratings_vector\"))\n",
    ").filter(col(\"num_ratings\") >= 5)\n",
    "\n",
    "sparse_vector_df.show()\n",
    "sparse_vector_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0aa360f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First two vectors: (611,[1,5,7,17,18,19,21,27,31,32,33,40,43,44,45,46,50,54,57,63,64,66,68,71,73,78,82,86,89,91,93,96,98,103,107,112,119,121,130,132,134,135,137,140,141,144,145,151,153,155,156,159,160,161,166,167,169,171,177,178,179,182,185,186,191,193,201,202,206,213,214,216,217,223,226,232,233,239,240,247,249,252,263,264,266,270,273,274,275,276,277,279,280,288,290,291,292,293,298,304,307,314,323,328,330,332,334,336,337,339,341,347,350,353,357,359,364,367,372,373,378,380,381,382,385,389,391,396,399,411,412,420,422,432,436,438,448,451,453,456,460,462,468,469,470,471,474,476,477,480,483,484,488,490,492,500,504,509,514,517,522,524,525,528,529,533,534,541,544,550,555,559,560,561,562,567,570,572,573,579,580,584,587,590,596,597,599,600,601,603,604,605,606,607,608,609,610],[4.0,4.0,4.5,4.5,3.5,4.0,3.5,3.0,5.0,3.0,3.0,5.0,5.0,3.0,4.0,5.0,3.0,3.0,5.0,5.0,4.0,4.0,2.5,5.0,4.5,4.0,2.5,4.0,3.0,4.0,3.0,5.0,4.5,4.0,4.0,3.0,3.5,4.0,3.0,2.0,3.0,4.0,4.0,3.0,4.0,3.5,5.0,5.0,2.0,3.0,4.0,4.5,4.0,4.0,5.0,3.5,4.5,5.0,5.0,4.0,4.0,4.0,4.0,4.0,4.0,2.0,5.0,4.0,5.0,3.5,3.0,3.0,4.0,3.5,3.5,3.5,3.0,4.0,5.0,5.0,4.0,4.5,4.0,4.0,2.0,5.0,5.0,4.0,5.0,4.0,4.0,3.0,4.5,4.5,4.0,4.0,4.0,3.0,2.0,5.0,4.0,3.0,3.5,5.0,4.0,4.0,3.5,4.0,4.0,4.0,5.0,5.0,4.0,5.0,5.0,4.0,5.0,5.0,3.0,3.0,4.5,5.0,3.5,4.5,4.0,5.0,3.0,5.0,4.0,5.0,2.0,4.0,4.0,2.5,4.0,4.5,5.0,5.0,5.0,5.0,4.5,1.5,4.0,4.0,4.0,5.0,4.0,4.0,4.0,3.0,4.0,4.5,4.5,3.5,4.0,4.0,4.0,4.0,4.0,4.0,3.0,4.0,4.0,2.5,3.0,5.0,4.0,3.0,3.0,4.0,4.0,5.0,3.0,4.0,4.5,3.5,4.0,4.0,5.0,4.0,3.0,5.0,5.0,4.0,4.0,4.0,3.0,2.5,4.0,4.0,3.0,4.0,2.5,4.0,2.5,3.0,5.0]) (611,[1,6,19,32,42,43,44,51,58,68,91,100,102,116,117,150,151,179,217,226,240,270,288,289,294,302,307,308,321,330,337,368,410,448,456,470,477,492,501,544,555,588,590,594,599,608],[4.0,5.0,3.0,3.0,4.0,5.0,3.0,4.0,3.0,2.0,3.0,3.5,5.0,3.5,3.0,3.0,3.0,4.0,1.0,3.5,4.0,3.0,4.0,2.5,1.0,3.0,3.5,0.5,3.0,3.0,4.0,3.0,4.0,3.0,3.0,3.0,3.0,4.0,5.0,3.0,5.0,3.0,3.0,4.0,1.5,2.0])\n",
      "Cosine similarity between first two vectors: 0.2696258459262343\n"
     ]
    }
   ],
   "source": [
    "# cosine similarity function\n",
    "def cosine_similarity(vec1: SparseVector, vec2: SparseVector) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the cosine similarity between two SparseVectors.\n",
    "    Values near 1 indicate high similarity, while values near 0 indicate low similarity.\n",
    "    \"\"\"\n",
    "    if vec1 is None or vec2 is None:\n",
    "        return None\n",
    "    dot_product = vec1.dot(vec2) # type: ignore\n",
    "    norm1 = vec1.norm(2)\n",
    "    norm2 = vec2.norm(2)\n",
    "    if norm1 == 0 or norm2 == 0:\n",
    "        return 0.0\n",
    "    return dot_product / (norm1 * norm2)\n",
    "\n",
    "v1 = sparse_vector_df.select(\"ratings_vector\").collect()[0][0]\n",
    "v2 = sparse_vector_df.select(\"ratings_vector\").collect()[2][0]\n",
    "print(\"First two vectors:\", v1, v2)\n",
    "similarity = cosine_similarity(v1, v2)\n",
    "print(\"Cosine similarity between first two vectors:\", similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e03d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-----------+--------------------+--------------------+\n",
      "|movieId|      ratings_vector|num_ratings|            features|              hashes|\n",
      "+-------+--------------------+-----------+--------------------+--------------------+\n",
      "|      1|(611,[1,5,7,17,18...|        197|(611,[1,5,7,17,18...|[[1.0], [-2.0], [...|\n",
      "|      2|(611,[6,8,18,19,2...|         94|(611,[6,8,18,19,2...|[[1.0], [2.0], [-...|\n",
      "|      3|(611,[1,6,19,32,4...|         46|(611,[1,6,19,32,4...|[[3.0], [3.0], [-...|\n",
      "|      4|(611,[6,14,84,262...|          6|(611,[6,14,84,262...|[[0.0], [-2.0], [...|\n",
      "|      5|(611,[6,31,43,45,...|         47|(611,[6,31,43,45,...|[[-4.0], [1.0], [...|\n",
      "+-------+--------------------+-----------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BUCKET_LENGTH = 0.01\n",
    "NUM_HASH_TABLES: int  = 30\n",
    "DISTANCE_THRESHOLD = 0.5\n",
    "\n",
    "@udf(returnType=VectorUDT())\n",
    "def normalize_vector(vector: SparseVector):\n",
    "    if vector is None or vector.values.size == 0:\n",
    "        return vector # or an empty vector of same size: Vectors.sparse(vector.size, [], [])\n",
    "    \n",
    "    mean_val = vector.values.mean()\n",
    "    new_values = vector.values - mean_val\n",
    "    norm_val = (new_values.dot(new_values)) ** 0.5\n",
    "    \n",
    "    if norm_val == 0.0:\n",
    "        norm_val = vector.norm(2)  # Fallback to L2 norm if the new values are all zero\n",
    "        return Vectors.sparse(\n",
    "            vector.size,\n",
    "            vector.indices,\n",
    "            vector.values / norm_val\n",
    "        )\n",
    "        \n",
    "    return Vectors.sparse(\n",
    "            vector.size,\n",
    "            vector.indices,\n",
    "            new_values / norm_val\n",
    "        )\n",
    "    \n",
    "df = sparse_vector_df.withColumn(\n",
    "        \"features\",\n",
    "        normalize_vector(col(\"ratings_vector\"))\n",
    "    )\n",
    "\n",
    "brp = BucketedRandomProjectionLSH(\n",
    "    inputCol=\"features\",\n",
    "    outputCol=\"hashes\",\n",
    "    bucketLength=BUCKET_LENGTH,\n",
    "    numHashTables=NUM_HASH_TABLES\n",
    ")\n",
    "\n",
    "model = brp.fit(df)\n",
    "transformed_df = model.transform(df)\n",
    "transformed_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a2869dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar movies to movieId 229 (took 1.98s):\n",
      "MovieId: 347, Similarity Score: 0.7282190812544191\n"
     ]
    }
   ],
   "source": [
    "def find_similar_movies(movie_vector_q: SparseVector):\n",
    "    \"\"\"\n",
    "    Find movies similar to the given movie_id based on the LSH model.\n",
    "    Returns a list of tuples (movieId, similarity_score).\n",
    "    \"\"\"\n",
    "    similar_movies = model.approxNearestNeighbors(\n",
    "        transformed_df,\n",
    "        movie_vector_q,\n",
    "        numNearestNeighbors=10,\n",
    "        distCol=\"distance\",\n",
    "    ).filter(\n",
    "        col(\"movieId\") != movie_id\n",
    "    ).withColumn(\n",
    "        \"distance\",\n",
    "        1-col(\"distance\") ** 2 / 2 # since A and B are normalized -> ∣∣A−B∣∣^2=2−2cos(θ) <=> cos(θ) = 1 - ∣∣A−B∣∣^2/2\n",
    "    ).filter(\n",
    "        col(\"distance\") > DISTANCE_THRESHOLD\n",
    "    ).select(\"movieId\", \"distance\")\n",
    "    return similar_movies.collect()\n",
    "# Example usage\n",
    "movie_id = 229  # Replace with the movieId you want to find similar movies for\n",
    "movie_vector = transformed_df.filter(col(\"movieId\") == movie_id).select(\"features\").first()[0]\n",
    "t = time.time()\n",
    "similar_movies = find_similar_movies(movie_vector)\n",
    "print(f\"Similar movies to movieId {movie_id} (took {time.time()-t:.2f}s):\")\n",
    "for movie, score in similar_movies:\n",
    "    print(f\"MovieId: {movie}, Similarity Score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "22f120a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate rating for userId 199 and movieId 229: 3.472315890264453 (actual rating: 3.0)\n"
     ]
    }
   ],
   "source": [
    "def approximate_rating(user_id: int, movie_id: int) -> float:\n",
    "    \"\"\"\n",
    "    Approximate the rating for a user and movie using the LSH model.\n",
    "    Returns the average rating of similar movies weighted by similarity.\n",
    "    \"\"\"\n",
    "    movie_vector = transformed_df.filter(col(\"movieId\") == movie_id).select(\"features\").first()[0]\n",
    "    similar_movies = find_similar_movies(movie_vector)\n",
    "    if not similar_movies:\n",
    "        return calculate_baseline_rating(user_id, movie_id)\n",
    "    \n",
    "    total_weighted_rating = 0.0\n",
    "    total_similarity = 0.0\n",
    "    \n",
    "    for sim_movie_id, similarity in similar_movies:\n",
    "        rating = train_df.filter(\n",
    "            (col(\"userId\") == user_id) & (col(\"movieId\") == sim_movie_id)\n",
    "        ).withColumn(\n",
    "            \"rating\",\n",
    "            col(\"rating\") - col(\"baseline_rating\")\n",
    "        ).select(\"rating\").first()\n",
    "        \n",
    "        if rating is not None:\n",
    "            total_weighted_rating += rating[0] * similarity\n",
    "            total_similarity += similarity\n",
    "            \n",
    "    if total_similarity == 0:\n",
    "        return calculate_baseline_rating(user_id, movie_id)\n",
    "    \n",
    "    return total_weighted_rating / total_similarity + calculate_baseline_rating(user_id, movie_id)\n",
    "\n",
    "# Example usage\n",
    "user_id = 199  \n",
    "movie_id = 229  \n",
    "approx_rating = approximate_rating(user_id, movie_id)\n",
    "actual_rating = train_df.filter(\n",
    "    (col('userId') == user_id) & (col('movieId') == movie_id)\n",
    ").select('rating').first()\n",
    "print(f\"Approximate rating for userId {user_id} and movieId {movie_id}: {approx_rating} (actual rating: {actual_rating[0] if actual_rating else 'N/A'})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9208fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_with_baseline = test_df.withColumn(\n",
    "    \"baseline_rating\",\n",
    "    calculate_baseline_rating_udf(col(\"userId\"), col(\"movieId\"))\n",
    ").withColumnRenamed(\"rating\", \"actual_rating\")\n",
    "\n",
    "test_movies_features = test_df_with_baseline.select(\"movieId\").distinct() \\\n",
    "    .join(transformed_df.select(\"movieId\", \"features\"), \"movieId\", \"inner\") \\\n",
    "    .withColumnRenamed(\"movieId\", \"test_movieId\") \\\n",
    "    .withColumnRenamed(\"features\", \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4793bb03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------------+\n",
      "|            datasetA|            datasetB|      raw_distance|\n",
      "+--------------------+--------------------+------------------+\n",
      "|{19, (611,[6,14,2...|{19, (611,[6,14,2...|               0.0|\n",
      "|{52, (611,[4,32,8...|{52, (611,[4,32,8...|               0.0|\n",
      "|{250, (611,[6,274...|{2208, (611,[186,...|0.8789764960572334|\n",
      "|{347, (611,[109,1...|{229, (611,[191,1...|0.7372664630180608|\n",
      "|{750, (611,[7,16,...|{750, (611,[7,16,...|               0.0|\n",
      "+--------------------+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12563"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DISTANCE_THRESHOLD_EUCLIDIAN = (2-2*DISTANCE_THRESHOLD)**0.5\n",
    "similar_movies_for_test = model.approxSimilarityJoin(\n",
    "    test_movies_features,\n",
    "    transformed_df.select(\"movieId\", \"features\"),\n",
    "    DISTANCE_THRESHOLD_EUCLIDIAN,\n",
    "    distCol=\"raw_distance\"\n",
    ")\n",
    "similar_movies_for_test.show(5)\n",
    "similar_movies_for_test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b73554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+------------------+\n",
      "|movieId|similar_movieId|        similarity|\n",
      "+-------+---------------+------------------+\n",
      "|    250|           2208|0.6137001596894742|\n",
      "|    347|            229|0.7282190812544191|\n",
      "|   1837|            725|0.7071067811865476|\n",
      "|   2841|          69849|0.6415411846289303|\n",
      "|   2883|           5428|0.7071067811865476|\n",
      "+-------+---------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_ratings_prep = similar_movies_for_test \\\n",
    "    .withColumn(\"similarity\", 1 - col(\"raw_distance\") ** 2 / 2) \\\n",
    "    .filter(col(\"similarity\") > DISTANCE_THRESHOLD) \\\n",
    "    .filter(col(\"datasetA.test_movieId\") != col(\"datasetB.movieId\")) \\\n",
    "    .select(\n",
    "        col(\"datasetA.test_movieId\").alias(\"movieId\"), # The movie from the test set\n",
    "        col(\"datasetB.movieId\").alias(\"similar_movieId\"), # A movie similar to the test movie\n",
    "        \"similarity\"\n",
    "    )\n",
    "predicted_ratings_prep.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97bb2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-------------+---------------+------------------+--------------------+-----------------------------+\n",
      "|userId|movieId|actual_rating|baseline_rating|        similarity|similar_movie_rating|similar_movie_baseline_rating|\n",
      "+------+-------+-------------+---------------+------------------+--------------------+-----------------------------+\n",
      "|    28|   2841|          2.5|      3.0604281|0.6415411846289303|                 3.5|                    2.6886334|\n",
      "|   600|   7004|          3.0|      2.4673922|0.6063390625908325|                 3.0|                    2.4673922|\n",
      "|   232|   8860|          3.0|      2.5806592|0.6433738724816302|                 3.0|                    2.5806592|\n",
      "|   474|  27912|          3.0|      3.2876277|0.6402779119256774|                 3.5|                    2.8501277|\n",
      "|   249|  33085|          2.5|      2.3897128| 0.661666819989295|                 4.0|                    3.6272128|\n",
      "+------+-------+-------------+---------------+------------------+--------------------+-----------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_with_test_info = test_df_with_baseline.alias(\"td\") \\\n",
    "    .join(predicted_ratings_prep.alias(\"prp\"), col(\"td.movieId\") == col(\"prp.movieId\"), \"inner\") \\\n",
    "    .select(\n",
    "        col(\"td.userId\"),\n",
    "        col(\"td.movieId\"),\n",
    "        col(\"td.actual_rating\"),\n",
    "        col(\"td.baseline_rating\"),\n",
    "        col(\"prp.similar_movieId\"),\n",
    "        col(\"prp.similarity\")\n",
    "    )\n",
    "\n",
    "final_predictions_data = predictions_with_test_info.alias(\"pti\") \\\n",
    "    .join(\n",
    "        train_df.alias(\"tnd\"),\n",
    "        (col(\"pti.userId\") == col(\"tnd.userId\")) & (col(\"pti.similar_movieId\") == col(\"tnd.movieId\")),\n",
    "        \"inner\" # Use inner join to only consider similar movies that the user has rated\n",
    "    ) \\\n",
    "    .select(\n",
    "        col(\"pti.userId\"),\n",
    "        col(\"pti.movieId\"),\n",
    "        col(\"pti.actual_rating\"),\n",
    "        col(\"pti.baseline_rating\"),\n",
    "        col(\"pti.similarity\"),\n",
    "        col(\"tnd.rating\").alias(\"similar_movie_rating\"),\n",
    "        col(\"tnd.baseline_rating\").alias(\"similar_movie_baseline_rating\")\n",
    "    )\n",
    "\n",
    "final_predictions_data.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba12d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Predicted Ratings (with similarity-based prediction):\n",
      "+------+-------+-------------+------------------+\n",
      "|userId|movieId|actual_rating|  predicted_rating|\n",
      "+------+-------+-------------+------------------+\n",
      "|    68|   2606|          2.5|3.7115384340286255|\n",
      "|   474|   4808|          2.0| 2.642857074737549|\n",
      "|   232|  51084|          3.5|3.4406007339496902|\n",
      "|   599|   3388|          3.0| 2.360421714121408|\n",
      "|   339|  81834|          2.5| 2.607619285583496|\n",
      "+------+-------+-------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_predicted_ratings_df = final_predictions_data.groupBy(\"userId\", \"movieId\", \"actual_rating\",\"baseline_rating\") \\\n",
    "    .agg(\n",
    "        (spark_sum((col(\"similar_movie_rating\")-col(\"similar_movie_baseline_rating\")) * col(\"similarity\")) / spark_sum(col(\"similarity\"))).alias(\"weighted_normalized_prediction\")\n",
    "    ) \\\n",
    "    .withColumn(\"predicted_rating\", col(\"weighted_normalized_prediction\") + col(\"baseline_rating\")) \\\n",
    "    .select(\"userId\", \"movieId\", \"actual_rating\", \"predicted_rating\")\n",
    "    \n",
    "print(\"\\nFinal Predicted Ratings (with similarity-based prediction):\")\n",
    "final_predicted_ratings_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c429ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Movies where only Baseline Rating is used as prediction:\n",
      "+------+-------+-------------+----------------+\n",
      "|userId|movieId|actual_rating|predicted_rating|\n",
      "+------+-------+-------------+----------------+\n",
      "|     4|    599|          2.0|       4.0745645|\n",
      "|    18|   1721|          4.0|       3.7142537|\n",
      "|    80|  85397|          4.0|        3.751777|\n",
      "|    95|   6934|          4.0|       3.6883564|\n",
      "|   105|  30812|          4.0|       4.1092324|\n",
      "+------+-------+-------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_without_similarity_prediction = test_df_with_baseline.alias(\"td\") \\\n",
    "    .join(final_predicted_ratings_df.alias(\"fpd\"),\n",
    "          (col(\"td.userId\") == col(\"fpd.userId\")) & (col(\"td.movieId\") == col(\"fpd.movieId\")),\n",
    "          \"left_anti\") \\\n",
    "    .select(\n",
    "        col(\"td.userId\"),\n",
    "        col(\"td.movieId\"),\n",
    "        col(\"td.actual_rating\"),\n",
    "        col(\"td.baseline_rating\").alias(\"predicted_rating\") # Use baseline as prediction\n",
    "    )\n",
    "\n",
    "print(\"\\nMovies where only Baseline Rating is used as prediction:\")\n",
    "movies_without_similarity_prediction.show(5)\n",
    "full_predicted_ratings_df = final_predicted_ratings_df.unionByName(movies_without_similarity_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a9ed77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full Predicted Ratings for Test Set:\n",
      "+------+-------+-------------+------------------+\n",
      "|userId|movieId|actual_rating|  predicted_rating|\n",
      "+------+-------+-------------+------------------+\n",
      "|    68|   2606|          2.5|3.7115384340286255|\n",
      "|   474|   4808|          2.0| 2.642857074737549|\n",
      "|   232|  51084|          3.5|3.4406007339496902|\n",
      "|   599|   3388|          3.0| 2.360421714121408|\n",
      "|   339|  81834|          2.5| 2.607619285583496|\n",
      "+------+-------+-------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "RMSE of LSH-based model on test set: 0.9075363974250692\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFull Predicted Ratings for Test Set:\")\n",
    "full_predicted_ratings_df.show(5)\n",
    "\n",
    "rmse_lsh = calculate_rmse(full_predicted_ratings_df)\n",
    "print(f\"\\nRMSE of LSH-based model on test set: {rmse_lsh}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
