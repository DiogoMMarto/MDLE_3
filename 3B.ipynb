{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cbf15282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyspark\n",
    "from pyspark.sql import SparkSession , DataFrame\n",
    "from pyspark.ml.feature import BucketedRandomProjectionLSH\n",
    "from pyspark.ml.linalg import SparseVector , VectorUDT , Vectors\n",
    "from pyspark.sql.functions import col, collect_list, struct , udf , avg\n",
    "from pyspark.sql.types import FloatType , ArrayType, StructType, StructField , IntegerType\n",
    "import collections\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2935eba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Eclipse Adoptium\\jdk-11.0.27.6-hotspot\\\n"
     ]
    }
   ],
   "source": [
    "# I need this to run comment this code if you don't need it\n",
    "os.environ['PYSPARK_PYTHON'] = '.venv/Scripts/python.exe'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = '.venv/Scripts/python.exe'\n",
    "print(os.environ.get(\"JAVA_HOME\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7966a21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark: SparkSession = SparkSession.builder \\\n",
    "    .appName(\"CF movielens\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cd97957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ratings: 100836\n",
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|     1|      1|   4.0|\n",
      "|     1|      3|   4.0|\n",
      "|     1|      6|   4.0|\n",
      "|     1|     47|   5.0|\n",
      "|     1|     50|   5.0|\n",
      "+------+-------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = \"ml-latest-small/ml-latest-small/ratings.csv\"\n",
    "ratings_df = spark.read.csv(file_path, header=True, inferSchema=True) \\\n",
    "    .drop(\"timestamp\")\n",
    "print(\"Number of ratings:\", ratings_df.count())\n",
    "ratings_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57ea1840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training ratings: 90673\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = ratings_df.randomSplit([0.9, 0.1], seed=42)\n",
    "print(\"Number of training ratings:\", train_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b12f65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average rating in training set: 3.503325135376573\n",
      "+------+---------------------+\n",
      "|userId|rating_deviation_user|\n",
      "+------+---------------------+\n",
      "|   148|  0.23417486462342696|\n",
      "|   463|   0.3932265887613582|\n",
      "|   471|   0.4057657737143363|\n",
      "|   496| -0.15147328352472123|\n",
      "|   243|    0.610960578909141|\n",
      "+------+---------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------+----------------------+\n",
      "|movieId|rating_deviation_movie|\n",
      "+-------+----------------------+\n",
      "|   1580|  -0.02144107740555823|\n",
      "|   2366|   0.13667486462342726|\n",
      "|   3175|   0.08363138636255751|\n",
      "|  32460|    0.7466748646234271|\n",
      "|   1238|    0.5522304201789825|\n",
      "+-------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+------+-------+---------------+\n",
      "|userId|movieId|baseline_rating|\n",
      "+------+-------+---------------+\n",
      "|     1|      1|      4.7871666|\n",
      "|     1|      3|      4.1031566|\n",
      "|     1|      6|       4.805284|\n",
      "|     1|     47|      4.8449597|\n",
      "|     1|     50|      5.1087117|\n",
      "+------+-------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_rating = train_df.agg({\"rating\": \"avg\"}).collect()[0][0]\n",
    "print(\"Average rating in training set:\", avg_rating)\n",
    "# (avg rating of user x ) - μ\n",
    "rating_deviation_of_user = train_df.groupBy(\"userId\") \\\n",
    "    .agg(avg(\"rating\").alias(\"avg_rating\")) \\\n",
    "    .withColumn(\"rating_deviation_user\", col(\"avg_rating\") - avg_rating) \\\n",
    "    .select(\"userId\", \"rating_deviation_user\")\n",
    "rating_deviation_of_user.show(5)\n",
    "rating_deviation_of_movie = train_df.groupBy(\"movieId\") \\\n",
    "    .agg(avg(\"rating\").alias(\"avg_rating\")) \\\n",
    "    .withColumn(\"rating_deviation_movie\", col(\"avg_rating\") - avg_rating) \\\n",
    "    .select(\"movieId\", \"rating_deviation_movie\")\n",
    "rating_deviation_of_movie.show(5)\n",
    "\n",
    "rating_deviation_of_user_dict = rating_deviation_of_user.rdd \\\n",
    "    .map(lambda row: (row.userId, row.rating_deviation_user)) \\\n",
    "    .collectAsMap()\n",
    "rating_deviation_of_movie_dict = rating_deviation_of_movie.rdd \\\n",
    "    .map(lambda row: (row.movieId, row.rating_deviation_movie)) \\\n",
    "    .collectAsMap()\n",
    "\n",
    "def calculate_baseline_rating(userId, movieId):\n",
    "    user_deviation = rating_deviation_of_user_dict.get(userId, 0.0)\n",
    "    movie_deviation = rating_deviation_of_movie_dict.get(movieId, 0.0)\n",
    "    return avg_rating + user_deviation + movie_deviation\n",
    "\n",
    "calculate_baseline_rating_udf = udf(calculate_baseline_rating, FloatType())\n",
    "\n",
    "train_df = train_df.withColumn(\n",
    "    \"baseline_rating\",\n",
    "    calculate_baseline_rating_udf(col(\"userId\"), col(\"movieId\"))\n",
    ")\n",
    "train_df.select(\"userId\", \"movieId\", \"baseline_rating\").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5fba961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|     1|    101|   5.0|\n",
      "|     1|    151|   5.0|\n",
      "|     1|    943|   4.0|\n",
      "|     1|   1031|   5.0|\n",
      "|     1|   1220|   5.0|\n",
      "+------+-------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af392025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of baseline model: 0.9062214757366772\n"
     ]
    }
   ],
   "source": [
    "# calculate RMSE\n",
    "def calculate_rmse(predictions):\n",
    "    predictions = predictions.withColumnRenamed(\"rating\", \"actual_rating\")\n",
    "    predictions = predictions.withColumnRenamed(\"predicted_rating\", \"predicted_rating\")\n",
    "    rmse = predictions.withColumn(\n",
    "        \"squared_error\",\n",
    "        (col(\"actual_rating\") - col(\"predicted_rating\")) ** 2\n",
    "    ).agg({\"squared_error\": \"avg\"}).collect()[0][0] ** 0.5\n",
    "    return rmse\n",
    "\n",
    "predicted_ratings_df = test_df.withColumn(\n",
    "    \"predicted_rating\",\n",
    "    calculate_baseline_rating_udf(col(\"userId\"), col(\"movieId\"))\n",
    ")\n",
    "rmse = calculate_rmse(predicted_ratings_df)\n",
    "print(\"RMSE of baseline model:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf077287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+--------------------+\n",
      "|userId|movieId|   normalized_rating|\n",
      "+------+-------+--------------------+\n",
      "|     1|      1| -0.7871665954589844|\n",
      "|     1|      3|-0.10315656661987305|\n",
      "|     1|      6| -0.8052840232849121|\n",
      "|     1|     47| 0.15504026412963867|\n",
      "|     1|     50|-0.10871171951293945|\n",
      "+------+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_norm_df = train_df.withColumn(\n",
    "    \"rating\",\n",
    "    col(\"rating\") - col(\"baseline_rating\")\n",
    ").withColumnRenamed(\"rating\", \"normalized_rating\") \\\n",
    ".select(\"userId\", \"movieId\", \"normalized_rating\")\n",
    "train_norm_df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90b18281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|movieId|      ratings_vector|\n",
      "+-------+--------------------+\n",
      "|      1|(611,[1,5,7,17,18...|\n",
      "|      2|(611,[6,8,18,19,2...|\n",
      "|      3|(611,[1,6,19,32,4...|\n",
      "|      4|(611,[6,14,84,262...|\n",
      "|      5|(611,[6,31,43,45,...|\n",
      "|      6|(611,[1,6,11,18,2...|\n",
      "|      7|(611,[6,14,19,31,...|\n",
      "|      8|(611,[6,20,43,274...|\n",
      "|      9|(611,[151,179,217...|\n",
      "|     10|(611,[6,8,11,19,2...|\n",
      "|     11|(611,[6,8,33,35,3...|\n",
      "|     12|(611,[19,44,120,1...|\n",
      "|     13|(611,[6,19,20,288...|\n",
      "|     14|(611,[90,109,182,...|\n",
      "|     15|(611,[6,19,93,136...|\n",
      "|     16|(611,[6,18,28,42,...|\n",
      "|     17|(611,[6,31,33,38,...|\n",
      "|     18|(611,[44,66,95,10...|\n",
      "|     19|(611,[6,14,21,40,...|\n",
      "|     20|(611,[78,199,217,...|\n",
      "+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9358"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_user = train_norm_df.select(\"userId\").distinct().count() +1\n",
    "\n",
    "@udf(returnType=VectorUDT())\n",
    "def build_sparse_vector(ratings):\n",
    "    user_rating_map = collections.OrderedDict(sorted([(r[0], r[1]) for r in ratings]))\n",
    "\n",
    "    user_ids = list(user_rating_map.keys())\n",
    "    values = list(user_rating_map.values())\n",
    "\n",
    "    return Vectors.sparse(length_user, user_ids, values)\n",
    "\n",
    "sparse_vector_df = train_norm_df.groupBy(\"movieId\") \\\n",
    "    .agg(collect_list(struct(\"userId\", \"normalized_rating\")).alias(\"ratings\")) \\\n",
    "    .select(\"movieId\", build_sparse_vector(col(\"ratings\")).alias(\"ratings_vector\"))\n",
    "sparse_vector_df.show()\n",
    "sparse_vector_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0aa360f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First two vectors: (611,[1,5,7,17,18,19,21,27,31,32,33,40,43,44,45,46,50,54,57,63,64,66,68,71,73,78,82,86,89,91,93,96,98,103,107,112,119,121,130,132,134,135,137,140,141,144,145,151,153,155,156,159,160,161,166,167,169,171,177,178,179,182,185,186,191,193,201,202,206,213,214,216,217,223,226,232,233,239,240,247,249,252,263,264,266,270,273,274,275,276,277,279,280,288,290,291,292,293,298,304,307,314,323,328,330,332,334,336,337,339,341,347,350,353,357,359,364,367,372,373,378,380,381,382,385,389,391,396,399,411,412,420,422,432,436,438,448,451,453,456,460,462,468,469,470,471,474,476,477,480,483,484,488,490,492,500,504,509,514,517,522,524,525,528,529,533,534,541,544,550,555,559,560,561,562,567,570,572,573,579,580,584,587,590,596,597,599,600,601,603,604,605,606,607,608,609,610],[-0.7871665954589844,-0.04973268508911133,0.849456787109375,-0.13986873626708984,-0.6643929481506348,0.9539303779602051,-0.1831974983215332,-0.9882071018218994,0.6734814643859863,-1.1497859954833984,-1.1918792724609375,0.7951216697692871,0.054163455963134766,-0.8027780055999756,-0.31270742416381836,0.5943150520324707,-0.2257380485534668,-0.4640183448791504,1.1764578819274902,0.9532814025878906,-0.20015859603881836,-0.44650793075561523,-1.1740005016326904,1.0238604545593262,0.3944516181945801,0.396587610244751,-1.306898593902588,-0.33367013931274414,-0.9088985919952393,0.19093656539916992,-1.7034120559692383,0.6098556518554688,0.13806486129760742,-0.32718658447265625,-0.3306851387023926,-1.0493292808532715,-1.1207890510559082,0.29480528831481934,-0.9106850624084473,-1.475701093673706,-0.9895086288452148,-0.042449951171875,-0.4154176712036133,-0.9351813793182373,0.02655172348022461,-0.5556850433349609,1.1193149089813232,1.0238604545593262,-0.6392738819122314,-0.9947876930236816,-0.09687423706054688,0.7759816646575928,0.875089168548584,-0.23068523406982422,0.49128007888793945,-0.37788987159729004,-0.17549848556518555,-0.05568504333496094,1.188450813293457,-0.5839109420776367,-0.22172975540161133,0.055600643157958984,-0.002113819122314453,-0.5083551406860352,-0.21549510955810547,-2.3277440071105957,0.46293210983276367,-0.24508953094482422,0.5258369445800781,-0.7362403869628906,-0.2878279685974121,-1.115999698638916,0.8056786060333252,-0.2027437686920166,-0.39162254333496094,-0.1813361644744873,-0.7148575782775879,-0.42281103134155273,0.646237850189209,0.8539867401123047,-0.12372303009033203,-0.05189704895019531,-0.16613483428955078,0.11013126373291016,-1.943343162536621,1.4114203453063965,0.5693149566650391,0.33055782318115234,0.4464101791381836,-0.7917962074279785,0.004097700119018555,-1.0809917449951172,0.19086217880249023,0.9103920459747314,-0.5854969024658203,-0.6640181541442871,0.27329516410827637,0.06931495666503906,-0.8030378818511963,0.6949429512023926,0.8918955326080322,-0.43985939025878906,-0.05859208106994629,1.3456308841705322,-0.11928129196166992,-0.018551349639892578,-0.3417961597442627,-0.7572154998779297,-0.6614542007446289,-0.5023269653320312,0.8483848571777344,1.0564944744110107,0.35309886932373047,1.1026482582092285,0.6202130317687988,0.11546874046325684,0.4193148612976074,0.7190155982971191,-0.7852303981781006,-0.5702199935913086,0.0915369987487793,0.8925471305847168,-0.4803304672241211,0.5445058345794678,0.16149377822875977,0.4784059524536133,-1.1663169860839844,1.449315071105957,-0.3277440071105957,1.3420422077178955,-2.3043694496154785,-0.28224754333496094,0.2681102752685547,-1.5946192741394043,0.3778257369995117,0.6865441799163818,1.7262299060821533,0.6338310241699219,0.6302471160888672,0.6745781898498535,-0.10831642150878906,-2.3246610164642334,0.12487053871154785,-0.1135554313659668,0.048188209533691406,0.6602239608764648,0.15336203575134277,-0.10256004333496094,-0.1533193588256836,-0.7157189846038818,-0.05095720291137695,0.24322795867919922,0.17715835571289062,-0.07631611824035645,-0.30455875396728516,0.35013699531555176,-0.3010554313659668,0.3452584743499756,0.26544761657714844,1.1660001277923584,-1.260293960571289,0.09517693519592285,0.025593042373657227,-1.5202374458312988,-0.6480762958526611,0.2121720314025879,-0.2596893310546875,-0.924018383026123,-1.693842887878418,-0.5378279685974121,0.10599446296691895,1.264627456665039,-1.0010552406311035,0.19735026359558105,-0.013209342956542969,0.8514788150787354,0.12487053871154785,-0.5348515510559082,0.3361058235168457,-0.40038204193115234,-0.9710495471954346,0.49036741256713867,0.6104106903076172,0.22435379028320312,0.0856637954711914,-0.44086313247680664,-0.0726161003112793,-0.901402473449707,-0.8491630554199219,0.08086228370666504,-0.9306850433349609,0.34766554832458496,-1.6068944931030273,-0.20507526397705078,-1.0634870529174805,-0.733715295791626,0.8788390159606934]) (611,[1,6,19,32,42,43,44,51,58,68,91,100,102,116,117,150,151,179,217,226,240,270,288,289,294,302,307,308,321,330,337,368,410,448,456,470,477,492,501,544,555,588,590,594,599,608],[-0.10315656661987305,1.7758164405822754,0.6379404067993164,-0.4657759666442871,0.6786415576934814,0.7381734848022461,-0.11876797676086426,0.4277799129486084,-0.6345252990722656,-0.9899904727935791,-0.12505316734313965,-0.19780278205871582,1.9003839492797852,0.24683165550231934,-0.09802627563476562,-0.3988487720489502,-0.2921295166015625,0.4622802734375,-1.5103111267089844,0.2923877239227295,0.3302481174468994,0.09543037414550781,1.0944023132324219,-0.9057657718658447,-1.3735783100128174,-0.8895320892333984,1.0759057998657227,-1.6395320892333984,-0.28513646125793457,-0.4352712631225586,0.022555828094482422,0.3979034423828125,0.2125089168548584,0.41023993492126465,-0.6414117813110352,-0.26780152320861816,-0.46930932998657227,0.37945127487182617,2.039039373397827,-1.0098328590393066,1.7900047302246094,0.05332517623901367,-0.09163618087768555,0.38196587562561035,-0.888606071472168,-0.8794770240783691])\n",
      "Cosine similarity between first two vectors: 0.09961966613742099\n"
     ]
    }
   ],
   "source": [
    "# cosine similarity function\n",
    "def cosine_similarity(vec1: SparseVector, vec2: SparseVector) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the cosine similarity between two SparseVectors.\n",
    "    Values near 1 indicate high similarity, while values near 0 indicate low similarity.\n",
    "    \"\"\"\n",
    "    if vec1 is None or vec2 is None:\n",
    "        return None\n",
    "    dot_product = vec1.dot(vec2) # type: ignore\n",
    "    norm1 = vec1.norm(2)\n",
    "    norm2 = vec2.norm(2)\n",
    "    if norm1 == 0 or norm2 == 0:\n",
    "        return 0.0\n",
    "    return dot_product / (norm1 * norm2)\n",
    "\n",
    "v1 = sparse_vector_df.select(\"ratings_vector\").collect()[0][0]\n",
    "v2 = sparse_vector_df.select(\"ratings_vector\").collect()[2][0]\n",
    "print(\"First two vectors:\", v1, v2)\n",
    "similarity = cosine_similarity(v1, v2)\n",
    "print(\"Cosine similarity between first two vectors:\", similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b319d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- ratings_vector: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sparse_vector_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c0e03d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+--------------------+\n",
      "|movieId|      ratings_vector|            features|              hashes|\n",
      "+-------+--------------------+--------------------+--------------------+\n",
      "|      1|(611,[1,5,7,17,18...|(611,[1,5,7,17,18...|[[-1.0], [-1.0], ...|\n",
      "|      2|(611,[6,8,18,19,2...|(611,[6,8,18,19,2...|[[-1.0], [-1.0], ...|\n",
      "|      3|(611,[1,6,19,32,4...|(611,[1,6,19,32,4...|[[-1.0], [-1.0], ...|\n",
      "|      4|(611,[6,14,84,262...|(611,[6,14,84,262...|[[-1.0], [-1.0], ...|\n",
      "|      5|(611,[6,31,43,45,...|(611,[6,31,43,45,...|[[-1.0], [-1.0], ...|\n",
      "+-------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NORMALIZE = True\n",
    "BUCKET_LENGTH = 0.1\n",
    "NUM_HASH_TABLES: int  = 20\n",
    "DISTANCE_THRESHOLD = 0.25\n",
    "\n",
    "@udf(returnType=VectorUDT())\n",
    "def normalize_vector(vector: SparseVector):\n",
    "    norm = vector.norm(2)\n",
    "    if norm == 0:\n",
    "        return \n",
    "    return Vectors.sparse(\n",
    "        vector.size,\n",
    "        vector.indices,\n",
    "        vector.values / norm\n",
    "    )\n",
    "    \n",
    "if NORMALIZE:\n",
    "    df = sparse_vector_df.withColumn(\n",
    "        \"features\",\n",
    "        normalize_vector(col(\"ratings_vector\"))\n",
    "    )\n",
    "else:\n",
    "    df = sparse_vector_df.withColumnRenamed(\"ratings_vector\", \"features\")\n",
    "\n",
    "brp = BucketedRandomProjectionLSH(\n",
    "    inputCol=\"features\",\n",
    "    outputCol=\"hashes\",\n",
    "    bucketLength=BUCKET_LENGTH,\n",
    "    numHashTables=NUM_HASH_TABLES\n",
    ")\n",
    "\n",
    "model = brp.fit(df)\n",
    "transformed_df = model.transform(df)\n",
    "transformed_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a2869dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar movies to movieId 1 (took 2.43s):\n",
      "MovieId: 3114, Similarity Score: 0.28742060925799084\n"
     ]
    }
   ],
   "source": [
    "def find_similar_movies(movie_vector_q: SparseVector):\n",
    "    \"\"\"\n",
    "    Find movies similar to the given movie_id based on the LSH model.\n",
    "    Returns a list of tuples (movieId, similarity_score).\n",
    "    \"\"\"\n",
    "    similar_movies = model.approxNearestNeighbors(\n",
    "        transformed_df,\n",
    "        movie_vector_q,\n",
    "        numNearestNeighbors=10,\n",
    "        distCol=\"distance\",\n",
    "    ).filter(\n",
    "        col(\"movieId\") != movie_id\n",
    "    ).withColumn(\n",
    "        \"distance\",\n",
    "        1-col(\"distance\") ** 2 / 2 # since A and B are normalized -> ∣∣A−B∣∣^2=2−2cos(θ) <=> cos(θ) = 1 - ∣∣A−B∣∣^2/2\n",
    "    ).filter(\n",
    "        col(\"distance\") > DISTANCE_THRESHOLD\n",
    "    ).select(\"movieId\", \"distance\")\n",
    "    return similar_movies.collect()\n",
    "# Example usage\n",
    "movie_id = 1  # Replace with the movieId you want to find similar movies for\n",
    "movie_vector = transformed_df.filter(col(\"movieId\") == movie_id).select(\"features\").first()[0]\n",
    "t = time.time()\n",
    "similar_movies = find_similar_movies(movie_vector)\n",
    "print(f\"Similar movies to movieId {movie_id} (took {time.time()-t:.2f}s):\")\n",
    "for movie, score in similar_movies:\n",
    "    print(f\"MovieId: {movie}, Similarity Score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "22f120a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate rating for userId 1 and movieId 101: 4.778156346104909 (actual rating: 5.0)\n"
     ]
    }
   ],
   "source": [
    "def approximate_rating(user_id: int, movie_id: int) -> float:\n",
    "    \"\"\"\n",
    "    Approximate the rating for a user and movie using the LSH model.\n",
    "    Returns the average rating of similar movies weighted by similarity.\n",
    "    \"\"\"\n",
    "    movie_vector = transformed_df.filter(col(\"movieId\") == movie_id).select(\"features\").first()[0]\n",
    "    similar_movies = find_similar_movies(movie_vector)\n",
    "    if not similar_movies:\n",
    "        return None\n",
    "    \n",
    "    total_weighted_rating = 0.0\n",
    "    total_similarity = 0.0\n",
    "    \n",
    "    for sim_movie_id, similarity in similar_movies:\n",
    "        rating = train_norm_df.filter(\n",
    "            (col(\"userId\") == user_id) & (col(\"movieId\") == sim_movie_id)\n",
    "        ).select(\"normalized_rating\").first()\n",
    "        \n",
    "        if rating is not None:\n",
    "            total_weighted_rating += rating[0] * similarity\n",
    "            total_similarity += similarity\n",
    "            \n",
    "    if total_similarity == 0:\n",
    "        return calculate_baseline_rating(user_id, movie_id)\n",
    "    \n",
    "    return total_weighted_rating / total_similarity + calculate_baseline_rating(user_id, movie_id)\n",
    "\n",
    "# Example usage\n",
    "user_id = 1  # Replace with the userId you want to approximate the rating for\n",
    "movie_id = 101  # Replace with the movieId you want to approximate the rating for\n",
    "approx_rating = approximate_rating(user_id, movie_id)\n",
    "print(f\"Approximate rating for userId {user_id} and movieId {movie_id}: {approx_rating} (actual rating: 5.0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4793bb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "DISTANCE_THRESHOLD_EUCLIDIAN = (2-2*DISTANCE_THRESHOLD)**0.5\n",
    "near_df = model.approxSimilarityJoin(\n",
    "    transformed_df.select(\"movieId\", \"features\").limit(1000),\n",
    "    transformed_df.select(\"movieId\", \"features\").limit(10000),\n",
    "    DISTANCE_THRESHOLD_EUCLIDIAN,\n",
    "    distCol=\"distance\"\n",
    ").withColumn(\n",
    "    \"distance\",\n",
    "    1 - col(\"distance\") ** 2 / 2  # since A and B are normalized -> ∣∣A−B∣∣^2=2−2cos(θ) <=> cos(θ) = 1 - ∣∣A−B∣∣^2/2\n",
    ").filter(\n",
    "    col(\"datasetA.movieId\") != col(\"datasetB.movieId\")\n",
    ").select(\n",
    "    col(\"datasetA.movieId\").alias(\"movieId_A\"),\n",
    "    col(\"datasetB.movieId\").alias(\"movieId_B\"),\n",
    "    \"distance\"\n",
    ")\n",
    "print(near_df.count())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
